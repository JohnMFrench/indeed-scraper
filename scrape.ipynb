{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Job Data from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will need to import several libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from re import A\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a class that will store job posts on Indeed\n",
    "All the relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just a utility function for printing to the console\n",
    "def printhr():\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "# This class will be created from data scraped from python\n",
    "# and converted to csv\n",
    "class JobPost:\n",
    "    def __init__(self, job_id, job_title, job_company, job_salary,\n",
    "                 location, job_date_posted, job_company_link, job_page_title, job_page_url):\n",
    "        self.job_id = job_id\n",
    "        self.job_title = job_title\n",
    "        self.job_company = job_company\n",
    "        self.job_date_posted = job_date_posted\n",
    "        self.job_company_link = job_company_link\n",
    "        self.job_salary = job_salary\n",
    "        self.location = location\n",
    "        self.job_page_title = job_page_title\n",
    "        self.job_page_url = job_page_url\n",
    "\n",
    "    # prints to console for debugging\n",
    "    def printF(self):\n",
    "        print(self.job_title)\n",
    "        print(f\"{self.job_company} at {self.location}\")\n",
    "        print(self.job_date_posted)\n",
    "        print(self.job_salary)\n",
    "        print(self.job_page_title)\n",
    "        print(self.job_company_link)\n",
    "        printhr()\n",
    "\n",
    "    # for debugging with less text\n",
    "    def desc(self):\n",
    "        print(self.job_title)\n",
    "        print(f\"{self.job_company} at {self.location}\")\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'job_id': self.job_id,\n",
    "            'job_title': self.job_title,\n",
    "            'job_company': self.job_company,\n",
    "            'job_date_posted': self.job_date_posted,\n",
    "            'job_company_link': self.job_company_link,\n",
    "            'job_salary': self.job_salary,\n",
    "            'location': self.location,\n",
    "            'job_page_title': self.job_page_title\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate a list\n",
    "This will contain all the job posts that we collect during the scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_post_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify some keywords that we will search for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"bootcamp\", \"SQL\", \"Tableau\", \"degree\", \"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask user for specific inputs\n",
    "This section requests specific inputs from the user and may not be necessary. running on default values for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using default vals\n",
      "Searching url https://www.indeed.com/jobs?q=data-analyst&no%20degree\n"
     ]
    }
   ],
   "source": [
    "#use_default_vals = input(\"Use default config? (Y/N)\")\n",
    "use_default_vals = \"Y\"\n",
    "while True:\n",
    "  if (use_default_vals.upper() == \"Y\"):\n",
    "    print(\"using default vals\")\n",
    "    job_query = quote(\"data-analyst\")\n",
    "    CompFilter = True\n",
    "    n = 15\n",
    "    deg = quote(\"no degree\")\n",
    "    url = \"https://www.indeed.com/jobs?q=\" + \\\n",
    "    job_query + \"&\" + deg\n",
    "    from_fs = False\n",
    "    print(f'Searching url {url}')\n",
    "    break\n",
    "  elif (use_default_vals.upper() == \"N\"):\n",
    "    print(\"input your own options to the parser\")\n",
    "    break\n",
    "  else:\n",
    "    \"did not recognize that. Your options are Y/N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "if from_fs:\n",
    "  html = open(\"pass1.html\", \"r\", encoding=\"utf8\")\n",
    "else: \n",
    "  html = urllib.request.urlopen(url).read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "job_lis = soup.find(\"ul\", \"jobsearch-ResultsList\")\n",
    "\n",
    "# SEPARATE VALUES RETURNED INTO DIVS THAT CONTAIN BOTH\n",
    "# .jobCard_mainContent AND .jobCardShelfContainer\n",
    "result_card_list = soup.find_all(\"result\")\n",
    "\n",
    "# FIND THE PARENT TAGS BY CSS CLASS\n",
    "results_list = soup.find_all(\"div\", class_=\"cardOutline\")\n",
    "#print(f\"Found {len(results_list)} job search results items \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function wil try to pull a salary from the salary-snippet-container div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A SEPARATE FUNCTION TO PARSE FOR SALARY CONTENT WITHIN THE JOB DIV\n",
    "def extract_job_salary(job_div_soup) -> str:\n",
    "  salary_divs = job_div_soup.find(\"div\", \"salary-snippet-container\")\n",
    "  salary = \"Compensation Not Listed\"\n",
    "  if salary_divs is not None:\n",
    "    salary_sub_div = salary_divs.find(\"div\")\n",
    "    for s in salary_sub_div.strings:\n",
    "      if s[0] == '$':\n",
    "        salary = s\n",
    "  return salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will pull a title from the job div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_title(job_div_soup) -> str:\n",
    "  title_h2 = result.find_all(\"h2\", class_=\"jobTitle\")\n",
    "  a_tag = title_h2[0].find(\"a\")\n",
    "  title = a_tag.string\n",
    "  return title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the indeed's job id from a job div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_id(job_soup_dev):\n",
    "    title_h2 = result.find_all(\"h2\", class_=\"jobTitle\")\n",
    "    a_tag = title_h2[0].find(\"a\")\n",
    "    job_id = a_tag[\"data-jk\"]\n",
    "    return job_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the job company from the job div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_company(job_soup_div):\n",
    "    company_span = result.find_all(\"span\", class_=\"companyName\")\n",
    "    for span in company_span:\n",
    "        if span.string[0] != '+':\n",
    "            company = span.string\n",
    "        else:\n",
    "            company = span[1].string\n",
    "    return company\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the indeed.com job url from job div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_url(job_soup_div) -> str:\n",
    "  # set a default value before attempting to parse text\n",
    "  company_link = \"Not found\"\n",
    "  company_link = result.find(\"a\", class_=\"jcs-JobTitle\")['href']\n",
    "  company_link = 'http://indeed.com' + company_link\n",
    "  return company_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the location from the job div if it is provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_location(job_soup_div) -> str:\n",
    "  # EXTRACT THE LOCATION\n",
    "  location_div = result.find(\"div\", \"companyLocation\")\n",
    "  location = location_div.string\n",
    "  if location is None:\n",
    "    location = \"not specified\"\n",
    "  return location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the time of the job was posted from the job div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_date_created(job_soup_div) -> str:\n",
    "    date_posted = \"Not specified when posted\"\n",
    "    date_spans = result.find_all(\"span\", class_=\"date\")\n",
    "    for d_span in date_spans:\n",
    "        if (d_span.string is not None):\n",
    "            date_posted = d_span.string\n",
    "    return date_posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_csv(jobs_post_list):\n",
    "  print(len(jobs_post_list))\n",
    "  jobs_df = pd.DataFrame.from_records([job.to_dict() for job in jobs_post_list])\n",
    "  #print(jobs_df.head())\n",
    "  print(jobs_df.describe)\n",
    "  jobs_df.to_csv('/data/job_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_page_url(jobs_soup_div, job_id)->str:\n",
    "  # Create a url for the job page using indeed's url query string\n",
    "  job_page_url = \"None found\"\n",
    "  job_page_url = \"https://www.indeed.com/viewjob?jk=\" + job_id\n",
    "  return job_page_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate Through the <table> Tag that contains job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 results\n"
     ]
    }
   ],
   "source": [
    "# ITERATE THROUGH THE <table> TAGS THAT CONTAIN JOB DATA\n",
    "i = 0\n",
    "\n",
    "print(f'Found {len(results_list)} results')\n",
    "for result in results_list:\n",
    "    # the for loop will be automatically be limited by the pagination on indeed\n",
    "    # limited to 15 results\n",
    "    if i < n:   # iterate for as many times as was specified by the config\n",
    "        len(f'Length of job list is {len(jobs_post_list)}')\n",
    "\n",
    "        salary_s = extract_job_salary(result)\n",
    "        title = extract_job_title(result)\n",
    "        job_id = extract_job_id(result)\n",
    "        company = extract_job_company(result)\n",
    "        company_url = extract_job_url(result)\n",
    "        location = extract_job_location(result)\n",
    "        date_created = extract_job_date_created(result)\n",
    "        job_page_url = extract_job_page_url(result, job_id)\n",
    "        try:\n",
    "            # Create a url for the job page using indeed's url query string\n",
    "            job_page_url = \"https://www.indeed.com/viewjob?jk=\" + job_id\n",
    "\n",
    "            # Create a new soup of job_page_url\n",
    "            job_html = urllib.request.urlopen(job_page_url).read()\n",
    "            job_soup = BeautifulSoup(job_html, \"html.parser\")\n",
    "            # Search the html soup for mentions of a specific keyword\n",
    "            for keyword in keywords:\n",
    "                data_mentions = job_soup.body.findAll(text=re.compile(keyword))\n",
    "                #print(f'{title} contains {len(data_mentions)} mentions of {keyword}')\n",
    "                #if keyword == \"Tableau\":\n",
    "                    #print(f'{title} contains {len(data_mentions)} mentions of {keyword}')\n",
    "            #print(job_page_url)\n",
    "\n",
    "            # IF THE SINGLE PAGE VIEW OF THE JOB, EXTRACT MORE DATA\n",
    "            posted = job_soup.find(\n",
    "                \"span\", class_=\"jobsearch-HiringInsights-entry--text\").string\n",
    "\n",
    "            # Instantiate JobPost class and append it to list\n",
    "            job = JobPost(job_id, title, company, salary_s, location,\n",
    "                          date_created, company_url, job_soup.title, job_page_url)\n",
    "            jobs_post_list.append(job)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        # finally iterate to the next \n",
    "        i = i + 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append the results to a csv if they are unique\n",
    "Used [this Stack Overflow post](https://stackoverflow.com/questions/34997174/how-to-convert-list-of-model-objects-to-pandas-dataframe) to figure out instantiating data frame from list of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df = pd.DataFrame.from_records([job.to_dict() for job in jobs_post_list])\n",
    "#print(jobs_df.describe)\n",
    "jobs_df.to_csv('data/job_posts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can iterate through job_post_list and print to console for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected 15\n",
      "1\n",
      "Data Analyst + Apprentice (Entry-Level)\n",
      "New Apprenticeship at not specified\n",
      "Not specified when posted\n",
      "$35,000 - $45,000 a year\n",
      "<title>Data Analyst + Apprentice (Entry-Level) - Richardson, TX 75082 - Indeed.com</title>\n",
      "http://indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0DTBj4QuFnqhUtF9Z2VxXbtwG9o9MshGMGKhqGuRanbG-me97CBnRil7bkHitbpmF59lGxPQTb9ALeWCeHPTnzCKSr_dvNOwQylk9gdiMfDmhBU0EmvOCmCSpPDnBag_N0GrY7CHWDG-adcJ-pfwcSqN_uv1SIR6l9k2U3Q4hlFlZsieCOerNrVfZOyGwFkjO4w6jJbKAenDlorVoW_DRNIlpTTfbouj7rhFDPa1jUc1f7QrDnBxrQvvC4EJc6cMVuA172xzXjcJ5VHPLClx9ASqINFAZTTzU6-boNM9jwKG-FX3tI0AmNwxM4odNOyTqRFHe6yw3reNMXI7KGDZjmn5QrGlKCoz8fYv39ddIP3i_L2KzZb2phGWnR8yKgUXeq5X5cTXKxKqve-DyJUOba_2YGcK49jPi2_fn2yW5wxr_xlOJikJGba&p=0&fvj=1&vjs=3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "2\n",
      "Data Analyst\n",
      "Delta Hire at Remote\n",
      "Not specified when posted\n",
      "$75,000 - $115,000 a year\n",
      "<title>Data Analyst - Remote - Indeed.com</title>\n",
      "http://indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0DzMqPHtizq4B_gJtT1ZvavnvoAyHFKLcaphdD20X80-zmjuv1rDuV8jz1T6Ux9T_t482Ep-BPAjfxsArnjkP28Zmw6LV2UfON-4hv1WobavPvDUXQNOf8xxrM5cGUSIgq494SfVzXniVu1O5xJdWtmyva4_V3H2wB2G-8JdOcDoNdpaPn20y-ZH3ykm2V4Ix_dgaHJdQgQX4FuP8JWOpm-uWhIImoRBtXseac1QNDj8D5omingpzEwNbmyQdkPmBEbWbCS6dT_lVF5uCcuIXQwJ196Q-4P9_SUC2fmBfYc67DD2waeJ0yRZdPPFV4wOVvufZZdI-_5rhQE0HEcOcrFvIwKnrck3vsURfrLBULyS0ZvwW0NzdjLaiY1UKIcuPj3R9P9dPQqcboaCHAwuYruhRWHmuf7oAXOIt9C2KgV9XsSRkngJXKHQkE7dYbIzX0qdw9xt9aQueCvXMZ2ziSn&p=1&fvj=1&vjs=3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "3\n",
      "Data Analyst\n",
      "Purdue University at not specified\n",
      "Not specified when posted\n",
      "Compensation Not Listed\n",
      "<title>Data Analyst - West Lafayette, IN 47906 - Indeed.com</title>\n",
      "http://indeed.com/rc/clk?jk=2917ef5d45319627&fccid=ac83e3328adafc41&vjs=3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "4\n",
      "Data Analyst Supporting the FBI\n",
      "FSA Federal at not specified\n",
      "Not specified when posted\n",
      "$25.29 an hour\n",
      "<title>Data Analyst Supporting the FBI - Quantico, VA 22134 - Indeed.com</title>\n",
      "http://indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0AK9q-cQKnf3DfHR64avwMzIcXVxwit4OIbhS0fZYeNhvY1IRVnFZKIZbSdKeT9HyqLkDqiz20BDS_wAxtSAqeBiSV3_qDmoJTgfAfeFDB4NgfycAzQj3UyQGQvv3YEFm1-ENhdxru-rT0QxcfAmbWnK5ISS2N-zJByC8MHBr6SNHEJJYz1d5BFjVFsIDrwTvlYz3mh_Y3zMybCNsj_XISzMn50FzKsBFrXxLH9uwqExBXr0GOA_ngqdI6YSIeOhLxtC-njJ6FnCt7rMi0uqnxWngQIjFlD0dmyx0_aqKVPUsiGTCkfJdOP_ksviXeuPXhU8PUgXzCeR4ikmrSgLoNozd9HnZCiXoLTD9Wl3oxog24i6xlFISg5HZaxdLOd3BvMoeHsNCaC-40a7AtjQpaPUsYorlgUzH0EFkKyGUinvfmA0cAbcTt8v1bvPfg-9tWrNjRJLMzI0-vZkAv1UZn4BIplDY8s-twBJ7zAstS6N2rPutxzLzfDldC03zbyw_RzV-WikulIA1W7SsXFfJ4AUoNiGJV7ZNxEhXp5czG9ZKsJU6ELl6MQRGiXo7K_qRru-8Z00H7sFkADTFywq0TYA0YLQ8Y4CNr4mEqyqUusb2-4pZYBL-Z2KPkJ_VL11kF-y0DgKGFYFDYBdrqMZz4Tuf9uyJ4fAzQ=&p=3&fvj=0&vjs=3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "5\n",
      "Senior Data Analyst\n",
      "Purdue University at Remote in West Lafayette, IN 47906\n",
      "Not specified when posted\n",
      "Compensation Not Listed\n",
      "<title>Senior Data Analyst - West Lafayette, IN 47906 - Indeed.com</title>\n",
      "http://indeed.com/rc/clk?jk=bd3981bb79fa1f59&fccid=ac83e3328adafc41&vjs=3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "6\n",
      "Data Analyst III\n",
      "Mississippi State Personnel Board at Hinds County, MS\n",
      "Not specified when posted\n",
      "$65,780 - $72,357 a year\n",
      "<title>Data Analyst III - Hinds County, MS - Indeed.com</title>\n",
      "http://indeed.com/rc/clk?jk=04df22e0fafa644a&fccid=953301e22be1f024&vjs=3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "7\n",
      "Data Analyst – Remote\n",
      "GenTech Associates at Remote in Richmond, VA 23219\n",
      "Not specified when posted\n",
      "$50 - $52 an hour\n",
      "<title>Data Analyst – Remote - Richmond, VA 23219 - Indeed.com</title>\n",
      "http://indeed.com/company/GenTech-Associates/jobs/Data-Analyst-Remote-62901918327f8b31?fccid=39879ca8bd0342f1&vjs=3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "8\n",
      "Data Analyst\n",
      "Hulu at Santa Monica, CA\n",
      "Not specified when posted\n",
      "Compensation Not Listed\n",
      "<title>Data Analyst - Santa Monica, CA - Indeed.com</title>\n",
      "http://indeed.com/rc/clk?jk=38d685cb5059bbd5&fccid=6824fc1f087bd63e&vjs=3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "9\n",
      "Jr. Data Analyst\n",
      "PepsiCo at not specified\n",
      "Not specified when posted\n",
      "Compensation Not Listed\n",
      "<title>Jr. Data Analyst - Chicago, IL - Indeed.com</title>\n",
      "http://indeed.com/company/PepsiCo/jobs/Junior-Data-Analyst-6f1a8e73e0ff6fc7?fccid=7ccab2fa064acd3a&vjs=3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "10\n",
      "Associate Data/Reporting Analyst\n",
      "Blizzard Entertainment at Irvine, CA 92618\n",
      "Not specified when posted\n",
      "Compensation Not Listed\n",
      "<title>Associate Data/Reporting Analyst - Irvine, CA 92618 - Indeed.com</title>\n",
      "http://indeed.com/rc/clk?jk=16e5a5f39d585bfa&fccid=645d83ee4cbe1d25&vjs=3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "11\n",
      "Junior Data Analyst\n",
      "TRESUME at Ashburn, VA\n",
      "Not specified when posted\n",
      "$26 - $32 an hour\n",
      "<title>Junior Data Analyst - Ashburn, VA - Indeed.com</title>\n",
      "http://indeed.com/company/TRESUME/jobs/Junior-Data-Analyst-c582e7975b8447bf?fccid=8456b57e4d97ccb6&vjs=3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "12\n",
      "Data Analyst (Urgent Hire)\n",
      "Streets Market at not specified\n",
      "Not specified when posted\n",
      "$60,000 - $78,000 a year\n",
      "<title>Data Analyst (Urgent Hire) - Washington, DC 20002 - Indeed.com</title>\n",
      "http://indeed.com/company/Streets-Market/jobs/Data-Analyst-5a04ae14bf44f6b4?fccid=a725b0bc218e6a1c&vjs=3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "13\n",
      "Data Analyst\n",
      "CDC Foundation at Hybrid remote in Pago Pago, AS 96799\n",
      "Not specified when posted\n",
      "$46,860 - $111,129 a year\n",
      "<title>Data Analyst - Pago Pago, AS 96799 - Indeed.com</title>\n",
      "http://indeed.com/company/CDC-Foundation-(-Contract)/jobs/Data-Analyst-531f2bd59d1ad191?fccid=985a660b16e6c129&vjs=3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "14\n",
      "Project Manager and/or Data Analyst Fellow\n",
      "Education Pioneers at not specified\n",
      "Not specified when posted\n",
      "$5,800 a month\n",
      "<title>Project Manager and/or Data Analyst Fellow - Memphis, TN - Indeed.com</title>\n",
      "http://indeed.com/company/Education-Pioneers/jobs/Project-Manager-or-Data-Analyst-Fellow-c51de3d5c868bf39?fccid=70eacd05f8f0f960&vjs=3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "15\n",
      "Senior Data Analyst\n",
      "Dollar Shave Club at Remote\n",
      "Not specified when posted\n",
      "$120,000 - $135,000 a year\n",
      "<title>Senior Data Analyst - Remote - Indeed.com</title>\n",
      "http://indeed.com/company/Mannai-IT/jobs/Senior-Data-Analyst-9f94efa59899650d?fccid=9a7f6b5a00c765be&vjs=3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"collected {len(jobs_post_list)}\")\n",
    "i1 = 1\n",
    "for job in jobs_post_list:\n",
    "    print(i1)\n",
    "    job.printF()\n",
    "    #job.desc()\n",
    "    i1 = i1 + 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "882ff7038df49cc7fe29560075f5cb1e01e62ef6492096b31436eb4923d2c412"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
