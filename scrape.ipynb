{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Job Data from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will need to import several libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import A\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a class that will store job posts on Indeed\n",
    "All the relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just a utility function for printing to the console\n",
    "def printhr():\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "# This class will be created from data scraped from python\n",
    "# and converted to csv\n",
    "class JobPost:\n",
    "    def __init__(self, job_id, job_title, job_company, job_salary,\n",
    "                 location, job_date_posted, job_company_link, job_page_title):\n",
    "        self.job_id = job_id\n",
    "        self.job_title = job_title\n",
    "        self.job_company = job_company\n",
    "        self.job_date_posted = job_date_posted\n",
    "        self.job_company_link = job_company_link\n",
    "        self.job_salary = job_salary\n",
    "        self.location = location\n",
    "        self.job_page_title = job_page_title\n",
    "\n",
    "    # prints to console for debugging\n",
    "    def printF(self):\n",
    "        print(self.job_title)\n",
    "        print(f\"{self.job_company} at {self.location}\")\n",
    "        print(self.job_date_posted)\n",
    "        print(self.job_salary)\n",
    "        print(self.job_page_title)\n",
    "        print(self.job_company_link)\n",
    "        printhr()\n",
    "\n",
    "    # for debugging with less text\n",
    "    def desc(self):\n",
    "        print(self.job_title)\n",
    "        print(f\"{self.job_company} at {self.location}\")\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'job_id': self.job_id,\n",
    "            'job_title': self.job_title,\n",
    "            'job_company': self.job_company,\n",
    "            'job_date_posted': self.job_date_posted,\n",
    "            'job_company_link': self.job_company_link,\n",
    "            'job_salary': self.job_salary,\n",
    "            'location': self.location,\n",
    "            'job_page_title': self.job_page_title\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate a list\n",
    "This will contain all the job posts that we collect during the scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_post_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify some keywords that we will search for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"bootcamp\", \"SQL\", \"Tableau\", \"degree\", \"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask user for specific inputs\n",
    "This section requests specific inputs from the user and may not be necessary. running on default values for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using default vals\n",
      "Searching url https://www.indeed.com/jobs?q=data-analyst&no%20degree\n"
     ]
    }
   ],
   "source": [
    "#use_default_vals = input(\"Use default config? (Y/N)\")\n",
    "use_default_vals = \"Y\"\n",
    "while True:\n",
    "  if (use_default_vals.upper() == \"Y\"):\n",
    "    print(\"using default vals\")\n",
    "    job_query = quote(\"data-analyst\")\n",
    "    CompFilter = True\n",
    "    n = 15\n",
    "    deg = quote(\"no degree\")\n",
    "    url = \"https://www.indeed.com/jobs?q=\" + \\\n",
    "    job_query + \"&\" + deg\n",
    "    from_fs = False\n",
    "    print(f'Searching url {url}')\n",
    "    break\n",
    "  elif (use_default_vals.upper() == \"N\"):\n",
    "    print(\"input your own options to the parser\")\n",
    "    break\n",
    "  else:\n",
    "    \"did not recognize that. Your options are Y/N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "if from_fs:\n",
    "  html = open(\"pass1.html\", \"r\", encoding=\"utf8\")\n",
    "else: \n",
    "  html = urllib.request.urlopen(url).read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "job_lis = soup.find(\"ul\", \"jobsearch-ResultsList\")\n",
    "\n",
    "# SEPARATE VALUES RETURNED INTO DIVS THAT CONTAIN BOTH\n",
    "# .jobCard_mainContent AND .jobCardShelfContainer\n",
    "result_card_list = soup.find_all(\"result\")\n",
    "\n",
    "# FIND THE PARENT TAGS BY CSS CLASS\n",
    "results_list = soup.find_all(\"div\", class_=\"cardOutline\")\n",
    "#print(f\"Found {len(results_list)} job search results items \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate Through the <table> Tag that contains job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 results\n",
      "154: Data Analyst contains 0 mentions of bootcamp\n",
      "154: Data Analyst contains 2 mentions of SQL\n",
      "154: Data Analyst contains 3 mentions of Tableau\n",
      "154: Data Analyst contains 0 mentions of degree\n",
      "154: Data Analyst contains 19 mentions of data\n",
      "https://www.indeed.com/viewjob?jk=93e90e27e10d3f1b\n",
      "Data Analyst contains 0 mentions of bootcamp\n",
      "Data Analyst contains 2 mentions of SQL\n",
      "Data Analyst contains 2 mentions of Tableau\n",
      "Data Analyst contains 0 mentions of degree\n",
      "Data Analyst contains 18 mentions of data\n",
      "https://www.indeed.com/viewjob?jk=38d685cb5059bbd5\n",
      "Data Analyst contains 0 mentions of bootcamp\n",
      "Data Analyst contains 0 mentions of SQL\n",
      "Data Analyst contains 0 mentions of Tableau\n",
      "Data Analyst contains 0 mentions of degree\n",
      "Data Analyst contains 19 mentions of data\n",
      "https://www.indeed.com/viewjob?jk=3886612c194ea1de\n",
      "Data Analyst contains 0 mentions of bootcamp\n",
      "Data Analyst contains 3 mentions of SQL\n",
      "Data Analyst contains 0 mentions of Tableau\n",
      "Data Analyst contains 0 mentions of degree\n",
      "Data Analyst contains 29 mentions of data\n",
      "https://www.indeed.com/viewjob?jk=ca94f80b933a44ba\n",
      "Data Analyst contains 0 mentions of bootcamp\n",
      "Data Analyst contains 2 mentions of SQL\n",
      "Data Analyst contains 2 mentions of Tableau\n",
      "Data Analyst contains 2 mentions of degree\n",
      "Data Analyst contains 24 mentions of data\n",
      "https://www.indeed.com/viewjob?jk=d21e40d081002c62\n",
      "Data Analyst contains 0 mentions of bootcamp\n",
      "Data Analyst contains 2 mentions of SQL\n",
      "Data Analyst contains 0 mentions of Tableau\n",
      "Data Analyst contains 0 mentions of degree\n",
      "Data Analyst contains 26 mentions of data\n",
      "https://www.indeed.com/viewjob?jk=e10283ee0e8cc137\n",
      "Data Analyst contains 0 mentions of bootcamp\n",
      "Data Analyst contains 0 mentions of SQL\n",
      "Data Analyst contains 3 mentions of Tableau\n",
      "Data Analyst contains 2 mentions of degree\n",
      "Data Analyst contains 23 mentions of data\n",
      "https://www.indeed.com/viewjob?jk=dedac1876187cf47\n",
      "Data Analyst contains 0 mentions of bootcamp\n",
      "Data Analyst contains 0 mentions of SQL\n",
      "Data Analyst contains 0 mentions of Tableau\n",
      "Data Analyst contains 0 mentions of degree\n",
      "Data Analyst contains 20 mentions of data\n",
      "https://www.indeed.com/viewjob?jk=bf5f42965b55f4fa\n",
      "Data Analyst / People Analytics contains 0 mentions of bootcamp\n",
      "Data Analyst / People Analytics contains 0 mentions of SQL\n",
      "Data Analyst / People Analytics contains 0 mentions of Tableau\n",
      "Data Analyst / People Analytics contains 2 mentions of degree\n",
      "Data Analyst / People Analytics contains 24 mentions of data\n",
      "https://www.indeed.com/viewjob?jk=40d7783fae883b07\n",
      "Data Analyst Remote role contains 0 mentions of bootcamp\n",
      "Data Analyst Remote role contains 2 mentions of SQL\n",
      "Data Analyst Remote role contains 0 mentions of Tableau\n",
      "Data Analyst Remote role contains 0 mentions of degree\n",
      "Data Analyst Remote role contains 19 mentions of data\n",
      "https://www.indeed.com/viewjob?jk=2910b3d3e37e42d9\n",
      "Data Analyst II contains 0 mentions of bootcamp\n",
      "Data Analyst II contains 3 mentions of SQL\n",
      "Data Analyst II contains 3 mentions of Tableau\n",
      "Data Analyst II contains 0 mentions of degree\n",
      "Data Analyst II contains 22 mentions of data\n",
      "https://www.indeed.com/viewjob?jk=86e8950addbbad3b\n",
      "Jr. Data Analyst contains 0 mentions of bootcamp\n",
      "Jr. Data Analyst contains 3 mentions of SQL\n",
      "Jr. Data Analyst contains 0 mentions of Tableau\n",
      "Jr. Data Analyst contains 0 mentions of degree\n",
      "Jr. Data Analyst contains 19 mentions of data\n",
      "https://www.indeed.com/viewjob?jk=1e9ba23166aa6793\n",
      "Data Analyst (all levels) contains 0 mentions of bootcamp\n",
      "Data Analyst (all levels) contains 0 mentions of SQL\n",
      "Data Analyst (all levels) contains 0 mentions of Tableau\n",
      "Data Analyst (all levels) contains 0 mentions of degree\n",
      "Data Analyst (all levels) contains 14 mentions of data\n",
      "https://www.indeed.com/viewjob?jk=f07756912b9fc020\n",
      "Data Analyst I (226 Days) contains 0 mentions of bootcamp\n",
      "Data Analyst I (226 Days) contains 0 mentions of SQL\n",
      "Data Analyst I (226 Days) contains 0 mentions of Tableau\n",
      "Data Analyst I (226 Days) contains 0 mentions of degree\n",
      "Data Analyst I (226 Days) contains 16 mentions of data\n",
      "https://www.indeed.com/viewjob?jk=9883337f6e7a537b\n",
      "Economic Data Analyst contains 0 mentions of bootcamp\n",
      "Economic Data Analyst contains 0 mentions of SQL\n",
      "Economic Data Analyst contains 0 mentions of Tableau\n",
      "Economic Data Analyst contains 0 mentions of degree\n",
      "Economic Data Analyst contains 17 mentions of data\n",
      "https://www.indeed.com/viewjob?jk=076e6ab808d08179\n"
     ]
    }
   ],
   "source": [
    "# ITERATE THROUGH THE <table> TAGS THAT CONTAIN JOB DATA\n",
    "i = 0\n",
    "\n",
    "print(f'Found {len(results_list)} results')\n",
    "for result in results_list:\n",
    "    # the for loop will be automatically be limited by the pagination on indeed\n",
    "    # limited to 15 results\n",
    "    if i < n:  # iterate for as many times as was specified by the config\n",
    "\n",
    "        # EXTRACT THE SALARY IF IT IS SHOWN ON THE JOBCARD\n",
    "        salary_divs = result.find(\"div\", \"salary-snippet-container\")\n",
    "        salary = \"Compensation Not Listed\"\n",
    "        if salary_divs is not None:\n",
    "            salary_sub_div = salary_divs.find(\"div\")\n",
    "            for s in salary_sub_div.strings:\n",
    "                if s[0] == '$':\n",
    "                    salary = s\n",
    "\n",
    "        # EXTRACT THE JOB TITLE\n",
    "        title_h2 = result.find_all(\"h2\", class_=\"jobTitle\")\n",
    "        a_tag = title_h2[0].find(\"a\")\n",
    "        title = a_tag.string\n",
    "\n",
    "        # EXTRACT JOB ID FROM DATA ATTRIBUTE\n",
    "        job_id = a_tag[\"data-jk\"]\n",
    "\n",
    "        # EXTRACT THE COMPANY\n",
    "        company_span = result.find_all(\"span\", class_=\"companyName\")\n",
    "        for span in company_span:\n",
    "            if span.string[0] != '+':\n",
    "                company = span.string\n",
    "            else:\n",
    "                company = span[1].string\n",
    "\n",
    "        # EXTRACT THE URL FOR THE JOB APPLICATION\n",
    "        company_link = result.find(\"a\", class_=\"jcs-JobTitle\")['href']\n",
    "        company_link = 'http://indeed.com' + company_link\n",
    "\n",
    "        # EXTRACT THE LOCATION\n",
    "        location_div = result.find(\"div\", \"companyLocation\")\n",
    "        location = location_div.string\n",
    "        if location is None:\n",
    "            location = \"not specified\"\n",
    "\n",
    "        # EXTRACT THE TIME THE JOB WAS POSTED date_posted =\n",
    "        date_posted = \"Not specified when posted\"\n",
    "        date_spans = result.find_all(\"span\", class_=\"date\")\n",
    "        for d_span in date_spans:\n",
    "            if (d_span.string is not None):\n",
    "                date_posted = d_span.string\n",
    "        try:\n",
    "            # Create a url for the job page using indeed's url query string\n",
    "            job_page_url = \"https://www.indeed.com/viewjob?jk=\" + job_id\n",
    "            #print(f'searching at job url {job_page_url}')\n",
    "\n",
    "            # Create a new soup of job_page_url\n",
    "            job_html = urllib.request.urlopen(job_page_url).read()\n",
    "            job_soup = BeautifulSoup(job_html, \"html.parser\")\n",
    "            # Search the html soup for mentions of a specific keyword\n",
    "            for keyword in keywords:\n",
    "                data_mentions = job_soup.body.findAll(text=re.compile(keyword))\n",
    "                print(f'{title} contains {len(data_mentions)} mentions of {keyword}')\n",
    "            print(job_page_url)\n",
    "\n",
    "            # IF THE SINGLE PAGE VIEW OF THE JOB, EXTRACT MORE DATA\n",
    "            posted = job_soup.find(\n",
    "                \"span\", class_=\"jobsearch-HiringInsights-entry--text\").string\n",
    "\n",
    "            # Instantiate JobPost class and append it to list\n",
    "            job = JobPost(job_id, title, company, salary, location,\n",
    "                          date_posted, company_link, job_soup.title)\n",
    "            jobs_post_list.append(job)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        # finally iterate to the next \n",
    "        i = i + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can iterate through job_post_list and print to console for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected 15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"collected {len(jobs_post_list)}\")\n",
    "i1 = 1\n",
    "for job in jobs_post_list:\n",
    "    #print(i1)\n",
    "    #job.desc()\n",
    "    i1 = i1 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append the results to a csv if they are unique\n",
    "Used [this Stack Overflow post](https://stackoverflow.com/questions/34997174/how-to-convert-list-of-model-objects-to-pandas-dataframe) to figure out instantiating data frame from list of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "             job_id          job_title                    job_company  \\\n",
      "0  93e90e27e10d3f1b  154: Data Analyst                      Dataspace   \n",
      "1  38d685cb5059bbd5       Data Analyst                           Hulu   \n",
      "2  3886612c194ea1de       Data Analyst     High Bridge Consulting LLC   \n",
      "3  ca94f80b933a44ba       Data Analyst  Westinghouse Electric Company   \n",
      "4  d21e40d081002c62       Data Analyst              Purdue University   \n",
      "\n",
      "             job_date_posted  \\\n",
      "0  Not specified when posted   \n",
      "1  Not specified when posted   \n",
      "2  Not specified when posted   \n",
      "3  Not specified when posted   \n",
      "4  Not specified when posted   \n",
      "\n",
      "                                    job_company_link               job_salary  \\\n",
      "0  http://indeed.com/rc/clk?jk=93e90e27e10d3f1b&f...        $65 - $75 an hour   \n",
      "1  http://indeed.com/rc/clk?jk=38d685cb5059bbd5&f...  Compensation Not Listed   \n",
      "2  http://indeed.com/company/High-Bridge-Consulti...        $25 - $35 an hour   \n",
      "3  http://indeed.com/rc/clk?jk=ca94f80b933a44ba&f...  Compensation Not Listed   \n",
      "4  http://indeed.com/company/Purdue-University/jo...  Compensation Not Listed   \n",
      "\n",
      "                  location                                    job_page_title  \n",
      "0            not specified       [154: Data Analyst - Illinois - Indeed.com]  \n",
      "1         Santa Monica, CA    [Data Analyst - Santa Monica, CA - Indeed.com]  \n",
      "2                   Remote              [Data Analyst - Remote - Indeed.com]  \n",
      "3  Remote in Cranberry, PA       [Data Analyst - Cranberry, PA - Indeed.com]  \n",
      "4            not specified  [Data Analyst - West Lafayette, IN - Indeed.com]  \n"
     ]
    }
   ],
   "source": [
    "print(len(jobs_post_list))\n",
    "# jobs_df = pd.DataFrame(jobs_post_list, columns=['job_id', 'job_title', 'job_company', 'job_salary',\n",
    "#                  'location', 'job_date_posted', 'job_company_link', 'job_page_title'])\n",
    "jobs_df = pd.DataFrame.from_records([job.to_dict() for job in jobs_post_list])\n",
    "print(jobs_df.head())\n",
    "jobs_df.to_csv('data/job_posts.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "882ff7038df49cc7fe29560075f5cb1e01e62ef6492096b31436eb4923d2c412"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
